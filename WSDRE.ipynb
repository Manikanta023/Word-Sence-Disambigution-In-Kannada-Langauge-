{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset Loading\n",
    "def load_dataset():\n",
    "    # Load WordNet dataset from NLTK\n",
    "    dataset = []\n",
    "    for synset in list(wn.all_synsets()):\n",
    "        word = synset.name().split('.')[0]\n",
    "        sense = synset.name().split('.')[1]\n",
    "        meaning = synset.definition()\n",
    "        dataset.append({'Word': word, 'Sense': sense, 'Meaning': meaning})\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing Functions\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Extraction Functions\n",
    "def extract_features(word):\n",
    "    # Example feature extraction: Part-of-speech tagging\n",
    "    pos_tags = pos_tag([word])\n",
    "    features = {'POS': pos_tags[0][1]}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Regular Expression Design\n",
    "def create_regex_pattern(word):\n",
    "    # Create a regular expression pattern for the word\n",
    "    pattern = rf\"\\b{word}\\b\"\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Rule-Based Disambiguation\n",
    "def rule_based_disambiguate_word(word, dataset, features):\n",
    "    # Iterate through the dataset and check for word matches\n",
    "    for index, row in dataset.iterrows():\n",
    "        if re.search(row['Word'], word):\n",
    "            # Check if all the features match\n",
    "            if all(feature in row for feature in features):\n",
    "                return row['Sense']\n",
    "\n",
    "    # If no match is found, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Training\n",
    "def train_model(dataset):\n",
    "    # Preprocess the dataset\n",
    "    dataset['Preprocessed'] = dataset['Meaning'].apply(preprocess_text)\n",
    "\n",
    "    # Extract features using TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(dataset['Preprocessed'])\n",
    "    y = dataset['Sense']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the LinearSVC model\n",
    "    model = LinearSVC()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model Prediction\n",
    "def predict_sense(text, dataset, model, vectorizer):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    words = preprocessed_text.split()\n",
    "    word_senses = {}\n",
    "    ambiguous_words = {}\n",
    "\n",
    "    for word in words:\n",
    "        features = extract_features(word)\n",
    "        sense = rule_based_disambiguate_word(word, dataset, features)\n",
    "        if sense is None:\n",
    "            X = vectorizer.transform([preprocessed_text])\n",
    "            predicted_sense = model.predict(X)\n",
    "            sense = predicted_sense[0]\n",
    "\n",
    "        if sense is not None:\n",
    "            if word in ambiguous_words:\n",
    "                ambiguous_words[word]['count'] += 1\n",
    "            else:\n",
    "                ambiguous_words[word] = {'count': 1, 'meanings': []}\n",
    "            word_senses[word] = sense\n",
    "            word_meaning = dataset.loc[(dataset['Word'] == word) & (dataset['Sense'] == sense), 'Meaning'].values\n",
    "            if len(word_meaning) > 0:\n",
    "                ambiguous_words[word]['meanings'].append(word_meaning[0])\n",
    "            else:\n",
    "                ambiguous_words[word]['meanings'].append('Meaning not found')\n",
    "\n",
    "    return word_senses, ambiguous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. User Interface Functions\n",
    "def disambiguate():\n",
    "    global input_text, dataset, model, vectorizer\n",
    "\n",
    "    text = input_text.get(\"1.0\", \"end\").strip()\n",
    "    if text:\n",
    "        word_senses, ambiguous_words = predict_sense(text, dataset, model, vectorizer)\n",
    "        ambiguous_words_count = len(ambiguous_words)\n",
    "        meanings = []\n",
    "\n",
    "        # Display ambiguous word senses count\n",
    "        messagebox.showinfo(\"Ambiguous Words Count\", f\"Ambiguous words count: {ambiguous_words_count}\")\n",
    "\n",
    "        # Display ambiguous word senses and their meanings\n",
    "        if ambiguous_words_count > 0:\n",
    "            for word in ambiguous_words:\n",
    "                meanings.append(f\"{word} : {', '.join(ambiguous_words[word]['meanings'])}\")\n",
    "\n",
    "        if meanings:\n",
    "            messagebox.showinfo(\"Word Senses\", \"\\n\".join(meanings))\n",
    "        else:\n",
    "            messagebox.showinfo(\"Word Senses\", \"No ambiguous words found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.838517763046065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\haris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\haris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\haris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\haris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\haris\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "                    0.00      0.00      0.00         2\n",
      "-bruno's-lily       0.00      0.00      0.00         1\n",
      "   22_caliber       0.00      0.00      0.00         1\n",
      "   45_caliber       0.00      0.00      0.00         0\n",
      " _elias_range       0.00      0.00      0.00         1\n",
      "  _petersburg       0.00      0.00      0.00         2\n",
      "            a       0.73      0.48      0.58      1500\n",
      "            k       0.00      0.00      0.00         1\n",
      "            n       0.88      0.96      0.92     16376\n",
      "            o       0.00      0.00      0.00         1\n",
      "            r       0.77      0.58      0.66       744\n",
      "            s       0.56      0.43      0.49      2183\n",
      "            v       0.80      0.72      0.76      2720\n",
      "\n",
      "     accuracy                           0.84     23532\n",
      "    macro avg       0.29      0.24      0.26     23532\n",
      " weighted avg       0.83      0.84      0.83     23532\n",
      "\n",
      "Accuracy: 0.838517763046065\n"
     ]
    }
   ],
   "source": [
    "def measure_performance(dataset, model, vectorizer):\n",
    "    # Prepare the test data\n",
    "    test_data = dataset.sample(frac=0.2, random_state=42)  # Use 20% of the dataset for testing\n",
    "    test_X = vectorizer.transform(test_data['Preprocessed'])\n",
    "    test_y = test_data['Sense']\n",
    "\n",
    "    # Predict the senses\n",
    "    predicted_y = model.predict(test_X)\n",
    "\n",
    "    # Calculate and display the classification report\n",
    "    report = classification_report(test_y, predicted_y)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Calculate and display the accuracy\n",
    "    accuracy = accuracy_score(test_y, predicted_y)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    global input_text, dataset, model, vectorizer\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset()\n",
    "\n",
    "    # Train the machine learning model\n",
    "    model, vectorizer = train_model(dataset)\n",
    "\n",
    "    # Measure the performance\n",
    "    measure_performance(dataset, model, vectorizer)\n",
    "\n",
    "    # Create the UI\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Word Sense Disambiguation\")\n",
    "    root.geometry(\"400x300\")\n",
    "\n",
    "    label = tk.Label(root, text=\"Enter a sentence:\")\n",
    "    label.pack()\n",
    "\n",
    "    input_text = tk.Text(root, height=5)\n",
    "    input_text.pack()\n",
    "\n",
    "    button = tk.Button(root, text=\"Disambiguate\", command=disambiguate)\n",
    "    button.pack()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
